{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries we may need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#modelling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df=pd.read_csv(r'C:\\Users\\Robin\\Downloads\\capstone_project\\_data\\credit-df-dataset-cleaned.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using log transformed data as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3913</td>\n",
       "      <td>3102</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2682</td>\n",
       "      <td>1725</td>\n",
       "      <td>2682</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29239</td>\n",
       "      <td>14027</td>\n",
       "      <td>13559</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>46990</td>\n",
       "      <td>48233</td>\n",
       "      <td>49291</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8617</td>\n",
       "      <td>5670</td>\n",
       "      <td>35835</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>188948</td>\n",
       "      <td>192815</td>\n",
       "      <td>208365</td>\n",
       "      <td>88004</td>\n",
       "      <td>31237</td>\n",
       "      <td>15980</td>\n",
       "      <td>8500</td>\n",
       "      <td>20000</td>\n",
       "      <td>5003</td>\n",
       "      <td>3047</td>\n",
       "      <td>5000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1683</td>\n",
       "      <td>1828</td>\n",
       "      <td>3502</td>\n",
       "      <td>8979</td>\n",
       "      <td>5190</td>\n",
       "      <td>0</td>\n",
       "      <td>1837</td>\n",
       "      <td>3526</td>\n",
       "      <td>8998</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3565</td>\n",
       "      <td>3356</td>\n",
       "      <td>2758</td>\n",
       "      <td>20878</td>\n",
       "      <td>20582</td>\n",
       "      <td>19357</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22000</td>\n",
       "      <td>4200</td>\n",
       "      <td>2000</td>\n",
       "      <td>3100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1645</td>\n",
       "      <td>78379</td>\n",
       "      <td>76304</td>\n",
       "      <td>52774</td>\n",
       "      <td>11855</td>\n",
       "      <td>48944</td>\n",
       "      <td>85900</td>\n",
       "      <td>3409</td>\n",
       "      <td>1178</td>\n",
       "      <td>1926</td>\n",
       "      <td>52964</td>\n",
       "      <td>1804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47929</td>\n",
       "      <td>48905</td>\n",
       "      <td>49764</td>\n",
       "      <td>36535</td>\n",
       "      <td>32428</td>\n",
       "      <td>15313</td>\n",
       "      <td>2078</td>\n",
       "      <td>1800</td>\n",
       "      <td>1430</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PAY_1  PAY_2  PAY_3  PAY_4  PAY_5  PAY_6  BILL_AMT1  BILL_AMT2  \\\n",
       "0          3      3      0      0     -1     -1       3913       3102   \n",
       "1          0      3      1      1      1      3       2682       1725   \n",
       "2          1      1      1      1      1      1      29239      14027   \n",
       "3          1      1      1      1      1      1      46990      48233   \n",
       "4          0      1      0      1      1      1       8617       5670   \n",
       "...      ...    ...    ...    ...    ...    ...        ...        ...   \n",
       "29995      1      1      1      1      1      1     188948     192815   \n",
       "29996      0      0      0      0      1      1       1683       1828   \n",
       "29997      5      4      3      0      1      1       3565       3356   \n",
       "29998      2      0      1      1      1      0      -1645      78379   \n",
       "29999      1      1      1      1      1      1      47929      48905   \n",
       "\n",
       "       BILL_AMT3  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  \\\n",
       "0            689          0          0          0         0       689   \n",
       "1           2682       3272       3455       3261         0      1000   \n",
       "2          13559      14331      14948      15549      1518      1500   \n",
       "3          49291      28314      28959      29547      2000      2019   \n",
       "4          35835      20940      19146      19131      2000     36681   \n",
       "...          ...        ...        ...        ...       ...       ...   \n",
       "29995     208365      88004      31237      15980      8500     20000   \n",
       "29996       3502       8979       5190          0      1837      3526   \n",
       "29997       2758      20878      20582      19357         0         0   \n",
       "29998      76304      52774      11855      48944     85900      3409   \n",
       "29999      49764      36535      32428      15313      2078      1800   \n",
       "\n",
       "       PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \n",
       "0             0         0         0         0  \n",
       "1          1000      1000         0      2000  \n",
       "2          1000      1000      1000      5000  \n",
       "3          1200      1100      1069      1000  \n",
       "4         10000      9000       689       679  \n",
       "...         ...       ...       ...       ...  \n",
       "29995      5003      3047      5000      1000  \n",
       "29996      8998       129         0         0  \n",
       "29997     22000      4200      2000      3100  \n",
       "29998      1178      1926     52964      1804  \n",
       "29999      1430      1000      1000      1000  \n",
       "\n",
       "[30000 rows x 18 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_df_log=credit_df.iloc[:,4:22]\n",
    "credit_df_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:402: RuntimeWarning: divide by zero encountered in log\n",
      "  result = func(self.values, **kwargs)\n",
      "c:\\Users\\Robin\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:402: RuntimeWarning: invalid value encountered in log\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "c=np.log(credit_df_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='BILL_AMT1', ylabel='Count'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for col in c.columns:\n",
    "#     plt.figure()\n",
    "#     plt.title(f'Feature: {col}')\n",
    "#     sns.histplot(c[col],bins=30)\n",
    "#     plt.show()\n",
    "sns.histplot(c['BILL_AMT1'])\n",
    "# seems to be more noramlly distributed now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_data=credit_df.iloc[:,0:4]\n",
    "log_df=pd.concat([demo_data,c],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.535241</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>6.535241</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>-inf</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>...</td>\n",
       "      <td>7.894318</td>\n",
       "      <td>8.093157</td>\n",
       "      <td>8.147578</td>\n",
       "      <td>8.089789</td>\n",
       "      <td>-inf</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>-inf</td>\n",
       "      <td>7.600902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.514806</td>\n",
       "      <td>9.570180</td>\n",
       "      <td>9.612333</td>\n",
       "      <td>9.651752</td>\n",
       "      <td>7.325149</td>\n",
       "      <td>7.313220</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>8.517193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.805497</td>\n",
       "      <td>10.251112</td>\n",
       "      <td>10.273636</td>\n",
       "      <td>10.293737</td>\n",
       "      <td>7.600902</td>\n",
       "      <td>7.610358</td>\n",
       "      <td>7.090077</td>\n",
       "      <td>7.003065</td>\n",
       "      <td>6.974479</td>\n",
       "      <td>6.907755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.486680</td>\n",
       "      <td>9.949416</td>\n",
       "      <td>9.859849</td>\n",
       "      <td>9.859065</td>\n",
       "      <td>7.600902</td>\n",
       "      <td>10.510014</td>\n",
       "      <td>9.210340</td>\n",
       "      <td>9.104980</td>\n",
       "      <td>6.535241</td>\n",
       "      <td>6.520621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>29996</td>\n",
       "      <td>220000</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.247047</td>\n",
       "      <td>11.385138</td>\n",
       "      <td>10.349359</td>\n",
       "      <td>9.679093</td>\n",
       "      <td>9.047821</td>\n",
       "      <td>9.903488</td>\n",
       "      <td>8.517793</td>\n",
       "      <td>8.021913</td>\n",
       "      <td>8.517193</td>\n",
       "      <td>6.907755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>29997</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.161090</td>\n",
       "      <td>9.102644</td>\n",
       "      <td>8.554489</td>\n",
       "      <td>-inf</td>\n",
       "      <td>7.515889</td>\n",
       "      <td>8.167919</td>\n",
       "      <td>9.104758</td>\n",
       "      <td>4.859812</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>29998</td>\n",
       "      <td>30000</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.922261</td>\n",
       "      <td>9.946451</td>\n",
       "      <td>9.932172</td>\n",
       "      <td>9.870809</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>9.998798</td>\n",
       "      <td>8.342840</td>\n",
       "      <td>7.600902</td>\n",
       "      <td>8.039157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>29999</td>\n",
       "      <td>80000</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-inf</td>\n",
       "      <td>...</td>\n",
       "      <td>11.242481</td>\n",
       "      <td>10.873774</td>\n",
       "      <td>9.380505</td>\n",
       "      <td>10.798432</td>\n",
       "      <td>11.360939</td>\n",
       "      <td>8.134174</td>\n",
       "      <td>7.071573</td>\n",
       "      <td>7.563201</td>\n",
       "      <td>10.877368</td>\n",
       "      <td>7.497762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>30000</td>\n",
       "      <td>50000</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.815047</td>\n",
       "      <td>10.506026</td>\n",
       "      <td>10.386778</td>\n",
       "      <td>9.636457</td>\n",
       "      <td>7.639161</td>\n",
       "      <td>7.495542</td>\n",
       "      <td>7.265430</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>6.907755</td>\n",
       "      <td>6.907755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  LIMIT_BAL  SEX  AGE     PAY_1     PAY_2     PAY_3  PAY_4  PAY_5  \\\n",
       "0          1      20000    1   24  1.098612  1.098612      -inf   -inf    NaN   \n",
       "1          2     120000    1   26      -inf  1.098612  0.000000    0.0    0.0   \n",
       "2          3      90000    1   34  0.000000  0.000000  0.000000    0.0    0.0   \n",
       "3          4      50000    1   37  0.000000  0.000000  0.000000    0.0    0.0   \n",
       "4          5      50000    0   57      -inf  0.000000      -inf    0.0    0.0   \n",
       "...      ...        ...  ...  ...       ...       ...       ...    ...    ...   \n",
       "29995  29996     220000    0   39  0.000000  0.000000  0.000000    0.0    0.0   \n",
       "29996  29997     150000    0   43      -inf      -inf      -inf   -inf    0.0   \n",
       "29997  29998      30000    0   37  1.609438  1.386294  1.098612   -inf    0.0   \n",
       "29998  29999      80000    0   41  0.693147      -inf  0.000000    0.0    0.0   \n",
       "29999  30000      50000    0   46  0.000000  0.000000  0.000000    0.0    0.0   \n",
       "\n",
       "          PAY_6  ...  BILL_AMT3  BILL_AMT4  BILL_AMT5  BILL_AMT6   PAY_AMT1  \\\n",
       "0           NaN  ...   6.535241       -inf       -inf       -inf       -inf   \n",
       "1      1.098612  ...   7.894318   8.093157   8.147578   8.089789       -inf   \n",
       "2      0.000000  ...   9.514806   9.570180   9.612333   9.651752   7.325149   \n",
       "3      0.000000  ...  10.805497  10.251112  10.273636  10.293737   7.600902   \n",
       "4      0.000000  ...  10.486680   9.949416   9.859849   9.859065   7.600902   \n",
       "...         ...  ...        ...        ...        ...        ...        ...   \n",
       "29995  0.000000  ...  12.247047  11.385138  10.349359   9.679093   9.047821   \n",
       "29996  0.000000  ...   8.161090   9.102644   8.554489       -inf   7.515889   \n",
       "29997  0.000000  ...   7.922261   9.946451   9.932172   9.870809       -inf   \n",
       "29998      -inf  ...  11.242481  10.873774   9.380505  10.798432  11.360939   \n",
       "29999  0.000000  ...  10.815047  10.506026  10.386778   9.636457   7.639161   \n",
       "\n",
       "        PAY_AMT2  PAY_AMT3  PAY_AMT4   PAY_AMT5  PAY_AMT6  \n",
       "0       6.535241      -inf      -inf       -inf      -inf  \n",
       "1       6.907755  6.907755  6.907755       -inf  7.600902  \n",
       "2       7.313220  6.907755  6.907755   6.907755  8.517193  \n",
       "3       7.610358  7.090077  7.003065   6.974479  6.907755  \n",
       "4      10.510014  9.210340  9.104980   6.535241  6.520621  \n",
       "...          ...       ...       ...        ...       ...  \n",
       "29995   9.903488  8.517793  8.021913   8.517193  6.907755  \n",
       "29996   8.167919  9.104758  4.859812       -inf      -inf  \n",
       "29997       -inf  9.998798  8.342840   7.600902  8.039157  \n",
       "29998   8.134174  7.071573  7.563201  10.877368  7.497762  \n",
       "29999   7.495542  7.265430  6.907755   6.907755  6.907755  \n",
       "\n",
       "[30000 rows x 22 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define target and feature columns\n",
    "y=credit_df['DEFAULT']\n",
    "X=credit_df.loc[:, credit_df.columns != 'DEFAULT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.78      0.88      5995\n",
      "           1       0.00      0.20      0.00         5\n",
      "\n",
      "    accuracy                           0.78      6000\n",
      "   macro avg       0.50      0.49      0.44      6000\n",
      "weighted avg       1.00      0.78      0.88      6000\n",
      "\n",
      "[[4679 1316]\n",
      " [   4    1]]\n",
      "\n",
      "Accuracy Score for model1 test:  0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,precision_score,recall_score,plot_confusion_matrix,classification_report\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "model1 = LogisticRegression()\n",
    "model1.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model1.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))\n",
    "print(confusion_matrix(y_pred, y_test))\n",
    "print('\\nAccuracy Score for model1 test: ', accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0007593014426727411"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8099166666666666"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.score(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=model1.score(X_train_scaled,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear that there is a bias towards the not default class. We will need to balance out the class by upsampling to get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9.1\n"
     ]
    }
   ],
   "source": [
    "import imblearn\n",
    "print(imblearn.__version__) # check it was installed properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "oversample=SMOTE()\n",
    "X_train,y_train = oversample.fit_resample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [30000, 46728]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Robin\\Downloads\\capstone_project\\_notebooks\\modelling.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Robin/Downloads/capstone_project/_notebooks/modelling.ipynb#ch0000028?line=0'>1</a>\u001b[0m predictors \u001b[39m=\u001b[39m credit_df\u001b[39m.\u001b[39mloc[:, credit_df\u001b[39m.\u001b[39mcolumns \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mDEFAULT\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Robin/Downloads/capstone_project/_notebooks/modelling.ipynb#ch0000028?line=1'>2</a>\u001b[0m oversample\u001b[39m=\u001b[39mSMOTE()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Robin/Downloads/capstone_project/_notebooks/modelling.ipynb#ch0000028?line=2'>3</a>\u001b[0m predictors,y \u001b[39m=\u001b[39m oversample\u001b[39m.\u001b[39;49mfit_resample(predictors,y)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Robin/Downloads/capstone_project/_notebooks/modelling.ipynb#ch0000028?line=4'>5</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(predictors, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Robin/Downloads/capstone_project/_notebooks/modelling.ipynb#ch0000028?line=5'>6</a>\u001b[0m model2\u001b[39m=\u001b[39mLogisticRegression()\n",
      "File \u001b[1;32mc:\\Users\\Robin\\anaconda3\\lib\\site-packages\\imblearn\\base.py:77\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     75\u001b[0m check_classification_targets(y)\n\u001b[0;32m     76\u001b[0m arrays_transformer \u001b[39m=\u001b[39m ArraysTransformer(X, y)\n\u001b[1;32m---> 77\u001b[0m X, y, binarize_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_X_y(X, y)\n\u001b[0;32m     79\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_strategy_ \u001b[39m=\u001b[39m check_sampling_strategy(\n\u001b[0;32m     80\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_strategy, y, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampling_type\n\u001b[0;32m     81\u001b[0m )\n\u001b[0;32m     83\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_resample(X, y)\n",
      "File \u001b[1;32mc:\\Users\\Robin\\anaconda3\\lib\\site-packages\\imblearn\\base.py:132\u001b[0m, in \u001b[0;36mBaseSampler._check_X_y\u001b[1;34m(self, X, y, accept_sparse)\u001b[0m\n\u001b[0;32m    130\u001b[0m     accept_sparse \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    131\u001b[0m y, binarize_y \u001b[39m=\u001b[39m check_target_type(y, indicate_one_vs_all\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 132\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, y, reset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accept_sparse\u001b[39m=\u001b[39;49maccept_sparse)\n\u001b[0;32m    133\u001b[0m \u001b[39mreturn\u001b[39;00m X, y, binarize_y\n",
      "File \u001b[1;32mc:\\Users\\Robin\\anaconda3\\lib\\site-packages\\sklearn\\base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    594\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    595\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 596\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\Robin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1092\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1074\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1075\u001b[0m     X,\n\u001b[0;32m   1076\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1087\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1088\u001b[0m )\n\u001b[0;32m   1090\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m-> 1092\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1094\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Users\\Robin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    385\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    386\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 387\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    390\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [30000, 46728]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "model2=LogisticRegression()\n",
    "model2.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred2 = model2.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred2, y_test))\n",
    "print(confusion_matrix(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7953333333333333"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knc = KNeighborsClassifier(n_neighbors=4)                         \n",
    "knc.fit(X_train_scaled,y_train)\n",
    "Y_pred_knc = knc.predict(X_test_scaled)\n",
    "accuracy_knc = accuracy_score(y_test,Y_pred_knc)\n",
    "accuracy_knc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous-multioutput and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Robin\\Downloads\\capstone_project\\_notebooks\\modelling.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Robin/Downloads/capstone_project/_notebooks/modelling.ipynb#ch0000009?line=0'>1</a>\u001b[0m \u001b[39m# recall_score(true labels, predicted labels)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Robin/Downloads/capstone_project/_notebooks/modelling.ipynb#ch0000009?line=1'>2</a>\u001b[0m recall_score(X_test_scaled, y_test)\n",
      "File \u001b[1;32mc:\\Users\\Robin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1901\u001b[0m, in \u001b[0;36mrecall_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1770\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrecall_score\u001b[39m(\n\u001b[0;32m   1771\u001b[0m     y_true,\n\u001b[0;32m   1772\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1778\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1779\u001b[0m ):\n\u001b[0;32m   1780\u001b[0m     \u001b[39m\"\"\"Compute the recall.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \n\u001b[0;32m   1782\u001b[0m \u001b[39m    The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1899\u001b[0m \u001b[39m    array([1. , 1. , 0.5])\u001b[39;00m\n\u001b[0;32m   1900\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1901\u001b[0m     _, r, _, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[0;32m   1902\u001b[0m         y_true,\n\u001b[0;32m   1903\u001b[0m         y_pred,\n\u001b[0;32m   1904\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   1905\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[0;32m   1906\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[0;32m   1907\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mrecall\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[0;32m   1908\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1909\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[0;32m   1910\u001b[0m     )\n\u001b[0;32m   1911\u001b[0m     \u001b[39mreturn\u001b[39;00m r\n",
      "File \u001b[1;32mc:\\Users\\Robin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1544\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1542\u001b[0m \u001b[39mif\u001b[39;00m beta \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1543\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mbeta should be >=0 in the F-beta score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1544\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[0;32m   1546\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1547\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Robin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1348\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1345\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m average_options \u001b[39mand\u001b[39;00m average \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1346\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39maverage has to be one of \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(average_options))\n\u001b[1;32m-> 1348\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m   1349\u001b[0m \u001b[39m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[0;32m   1350\u001b[0m \u001b[39m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[0;32m   1351\u001b[0m present_labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[1;32mc:\\Users\\Robin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous-multioutput and binary targets"
     ]
    }
   ],
   "source": [
    "# recall_score(true labels, predicted labels)\n",
    "recall_score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83975"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knc.score(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_pred_knc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Robin\\Downloads\\capstone_project\\_notebooks\\modelling.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Robin/Downloads/capstone_project/_notebooks/modelling.ipynb#ch0000015?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m plot_confusion_matrix\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Robin/Downloads/capstone_project/_notebooks/modelling.ipynb#ch0000015?line=3'>4</a>\u001b[0m plot_confusion_matrix(Y_pred_knc, y_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_pred_knc' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "\n",
    "plot_confusion_matrix(Y_pred_knc, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "SVM_model = LinearSVC()\n",
    "SVM_model.fit(X_train_scaled, y_train)\n",
    "Y_pred_svm = SVM_model.predict(X_test_scaled)\n",
    "\n",
    "print(f\"The TRAIN classification accuracy is: {SVM_model.score(X_train, y_train)}\")\n",
    "recall_score(y_test, Y_pred_svm)\n",
    "accuracy_svm = accuracy_score(y_test,Y_pred_svm)\n",
    "accuracy_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "accuracies = []\n",
    "precision = []\n",
    "recall = []\n",
    "for d in range(1,10):\n",
    "    model1 = DecisionTreeClassifier(max_depth=d)\n",
    "    model1.fit(X_train_scaled, y_train)\n",
    "    y_pred = model1.predict(X_test_scaled)\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    precision.append(precision_score(y_test, y_pred))\n",
    "    recall.append(recall_score(y_test, y_pred))\n",
    "    print(\"Max Depth: \", d)\n",
    "    print(classification_report(y_pred, y_test))\n",
    "    print(confusion_matrix(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "fcb6c75713917bbeb6c7e52097ffadadbac73d1b7694c3ec4fe4848cb90a5430"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
