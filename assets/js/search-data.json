{
  
    
        "post0": {
            "title": "Title",
            "content": "import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns . credit_df=pd.read_csv(r&#39;C: Users Robin Downloads capstone_project _data taiwan_data_categorical.csv&#39;) . credit_df . ID LIMIT_BAL SEX EDUCATION MARRIAGE AGE PAY_0 PAY_2 PAY_3 PAY_4 ... BILL_AMT4 BILL_AMT5 BILL_AMT6 PAY_AMT1 PAY_AMT2 PAY_AMT3 PAY_AMT4 PAY_AMT5 PAY_AMT6 default payment next month . 0 1 | 20000 | Female | University Graduate | Married | 24 | 2 | 2 | -1 | -1 | ... | 0 | 0 | 0 | 0 | 689 | 0 | 0 | 0 | 0 | 1 | . 1 2 | 120000 | Female | University Graduate | Single | 26 | -1 | 2 | 0 | 0 | ... | 3272 | 3455 | 3261 | 0 | 1000 | 1000 | 1000 | 0 | 2000 | 1 | . 2 3 | 90000 | Female | University Graduate | Single | 34 | 0 | 0 | 0 | 0 | ... | 14331 | 14948 | 15549 | 1518 | 1500 | 1000 | 1000 | 1000 | 5000 | 0 | . 3 4 | 50000 | Female | University Graduate | Married | 37 | 0 | 0 | 0 | 0 | ... | 28314 | 28959 | 29547 | 2000 | 2019 | 1200 | 1100 | 1069 | 1000 | 0 | . 4 5 | 50000 | Male | University Graduate | Married | 57 | -1 | 0 | -1 | 0 | ... | 20940 | 19146 | 19131 | 2000 | 36681 | 10000 | 9000 | 689 | 679 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 29995 29996 | 220000 | Male | High School | Married | 39 | 0 | 0 | 0 | 0 | ... | 88004 | 31237 | 15980 | 8500 | 20000 | 5003 | 3047 | 5000 | 1000 | 0 | . 29996 29997 | 150000 | Male | High School | Single | 43 | -1 | -1 | -1 | -1 | ... | 8979 | 5190 | 0 | 1837 | 3526 | 8998 | 129 | 0 | 0 | 0 | . 29997 29998 | 30000 | Male | University Graduate | Single | 37 | 4 | 3 | 2 | -1 | ... | 20878 | 20582 | 19357 | 0 | 0 | 22000 | 4200 | 2000 | 3100 | 1 | . 29998 29999 | 80000 | Male | High School | Married | 41 | 1 | -1 | 0 | 0 | ... | 52774 | 11855 | 48944 | 85900 | 3409 | 1178 | 1926 | 52964 | 1804 | 1 | . 29999 30000 | 50000 | Male | University Graduate | Married | 46 | 0 | 0 | 0 | 0 | ... | 36535 | 32428 | 15313 | 2078 | 1800 | 1430 | 1000 | 1000 | 1000 | 1 | . 30000 rows × 25 columns . sns.histplot(credit_df[&#39;SEX&#39;]) . &lt;AxesSubplot:xlabel=&#39;SEX&#39;, ylabel=&#39;Count&#39;&gt; . sns.countplot(credit_df[&#39;SEX&#39;],palette=&quot;Set2&quot;) . C: Users Robin anaconda3 lib site-packages seaborn _decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation. warnings.warn( . &lt;AxesSubplot:xlabel=&#39;SEX&#39;, ylabel=&#39;count&#39;&gt; . sns.countplot(credit_df[&#39;MARRIAGE&#39;],palette=&quot;Set2&quot;) . C: Users Robin anaconda3 lib site-packages seaborn _decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation. warnings.warn( . &lt;AxesSubplot:xlabel=&#39;MARRIAGE&#39;, ylabel=&#39;count&#39;&gt; . education_percentage=credit_df[&#39;EDUCATION&#39;].value_counts(normalize=True)*100 . education_percentage.index . Index([&#39;University Graduate&#39;, &#39;Graduate school&#39;, &#39;High school&#39;, &#39;Unknown&#39;, &#39;other&#39;, &#39;not known&#39;, &#39;not known 1&#39;], dtype=&#39;object&#39;) . plt.figure(figsize=(12,7)) sns.barplot(x=education_percentage.index,y=education_percentage.values,palette=&#39;muted&#39;) plt.ylabel(&#39;Percentage&#39;) plt.title(&#39;Percentage of Education&#39;) plt.xlabel(&#39;Education&#39;) plt.show() . education_percentage.plot(kind=&#39;bar&#39;) . &lt;AxesSubplot:&gt; . credit_df[&#39;EDUCATION&#39;].value_counts() . University Graduate 14030 Graduate school 10585 High school 4917 Unknown 280 other institutions 123 Not recognised 51 Not recognised 1 14 Name: EDUCATION, dtype: int64 . # Marriage, Age, and Sex def boxplot_variation(feature1, feature2, feature3, width=16): fig, ax1 = plt.subplots(ncols=1, figsize=(width, 6)) s = sns.boxplot(ax=ax1, x=feature1, y=feature2, hue=feature3, data=credit_df, palette=&#39;pastel&#39;) #s.set_xticklabels(s.get_xticklabels(), rotation=90) plt.show(); boxplot_variation(&#39;MARRIAGE&#39;, &#39;AGE&#39;, &#39;SEX&#39;,10) . credit_df[&#39;LIMIT_BAL&#39;].value_counts() . 50000 3365 20000 1976 30000 1610 80000 1567 200000 1528 ... 730000 2 1000000 1 327680 1 760000 1 690000 1 Name: LIMIT_BAL, Length: 81, dtype: int64 . plt.figure(figsize = (14,6)) plt.title(&#39;Amount of credit limit &#39;) sns.histplot(credit_df[&#39;LIMIT_BAL&#39;],bins=40) plt.show() . plt.figure(figsize = (14,6)) plt.title(&#39;Amount of credit limit - Density Plot&#39;) sns.set_color_codes(&quot;pastel&quot;) sns.distplot(credit_df[&#39;LIMIT_BAL&#39;],kde=True,bins=200) plt.show() . C: Users Robin anaconda3 lib site-packages seaborn distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms). warnings.warn(msg, FutureWarning) .",
            "url": "https://apayal.github.io/capstone_project/2022/08/01/same.html",
            "relUrl": "/2022/08/01/same.html",
            "date": " • Aug 1, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Title",
            "content": "Modelling . import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns #modelling from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler . credit_df=pd.read_csv(r&#39;C: Users Robin Downloads capstone_project _data credit-df-dataset-cleaned.csv&#39;) # change to the cleaned dataset . We will be using log transformed data as . credit_df_log=credit_df.iloc[:,4:22] credit_df_log . PAY_1 PAY_2 PAY_3 PAY_4 PAY_5 PAY_6 BILL_AMT1 BILL_AMT2 BILL_AMT3 BILL_AMT4 BILL_AMT5 BILL_AMT6 PAY_AMT1 PAY_AMT2 PAY_AMT3 PAY_AMT4 PAY_AMT5 PAY_AMT6 . 0 3 | 3 | 0 | 0 | -1 | -1 | 3913 | 3102 | 689 | 0 | 0 | 0 | 0 | 689 | 0 | 0 | 0 | 0 | . 1 0 | 3 | 1 | 1 | 1 | 3 | 2682 | 1725 | 2682 | 3272 | 3455 | 3261 | 0 | 1000 | 1000 | 1000 | 0 | 2000 | . 2 1 | 1 | 1 | 1 | 1 | 1 | 29239 | 14027 | 13559 | 14331 | 14948 | 15549 | 1518 | 1500 | 1000 | 1000 | 1000 | 5000 | . 3 1 | 1 | 1 | 1 | 1 | 1 | 46990 | 48233 | 49291 | 28314 | 28959 | 29547 | 2000 | 2019 | 1200 | 1100 | 1069 | 1000 | . 4 0 | 1 | 0 | 1 | 1 | 1 | 8617 | 5670 | 35835 | 20940 | 19146 | 19131 | 2000 | 36681 | 10000 | 9000 | 689 | 679 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 29995 1 | 1 | 1 | 1 | 1 | 1 | 188948 | 192815 | 208365 | 88004 | 31237 | 15980 | 8500 | 20000 | 5003 | 3047 | 5000 | 1000 | . 29996 0 | 0 | 0 | 0 | 1 | 1 | 1683 | 1828 | 3502 | 8979 | 5190 | 0 | 1837 | 3526 | 8998 | 129 | 0 | 0 | . 29997 5 | 4 | 3 | 0 | 1 | 1 | 3565 | 3356 | 2758 | 20878 | 20582 | 19357 | 0 | 0 | 22000 | 4200 | 2000 | 3100 | . 29998 2 | 0 | 1 | 1 | 1 | 0 | -1645 | 78379 | 76304 | 52774 | 11855 | 48944 | 85900 | 3409 | 1178 | 1926 | 52964 | 1804 | . 29999 1 | 1 | 1 | 1 | 1 | 1 | 47929 | 48905 | 49764 | 36535 | 32428 | 15313 | 2078 | 1800 | 1430 | 1000 | 1000 | 1000 | . 30000 rows × 18 columns . c=np.log(credit_df_log) . c: Users Robin anaconda3 lib site-packages pandas core internals blocks.py:402: RuntimeWarning: divide by zero encountered in log result = func(self.values, **kwargs) c: Users Robin anaconda3 lib site-packages pandas core internals blocks.py:402: RuntimeWarning: invalid value encountered in log result = func(self.values, **kwargs) . # plt.figure() # plt.title(f&#39;Feature: {col}&#39;) # sns.histplot(c[col],bins=30) # plt.show() . y=credit_df[&#39;DEFAULT&#39;] X=credit_df.loc[:, credit_df.columns != &#39;DEFAULT&#39;] . target = credit_df[&#39;DEFAULT&#39;] predictors = credit_df.loc[:, credit_df.columns != &#39;DEFAULT&#39;] X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10) scaler = StandardScaler() X_train_scaled = scaler.fit_transform(X_train) X_test_scaled = scaler.transform(X_test) . from sklearn.linear_model import LogisticRegression from sklearn.metrics import accuracy_score,confusion_matrix,precision_score,recall_score,plot_confusion_matrix,classification_report model1 = LogisticRegression() model1.fit(X_train_scaled, y_train) y_pred = model1.predict(X_test) print(classification_report(y_pred, y_test)) print(confusion_matrix(y_pred, y_test)) print(&#39; nAccuracy Score for model1 test: &#39;, accuracy_score(y_pred,y_test)) . precision recall f1-score support 0 1.00 0.78 0.88 5995 1 0.00 0.20 0.00 5 accuracy 0.78 6000 macro avg 0.50 0.49 0.44 6000 weighted avg 1.00 0.78 0.88 6000 [[4679 1316] [ 4 1]] Accuracy Score for model1 test: 0.78 . c: Users Robin anaconda3 lib site-packages sklearn base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names warnings.warn( . recall_score(y_test, y_pred) . model1.score(X_train_scaled,y_train) . 0.8099166666666666 . from sklearn.neighbors import KNeighborsClassifier knc = KNeighborsClassifier(n_neighbors=4) knc.fit(X_train_scaled,y_train) Y_pred_knc = knc.predict(X_test_scaled) accuracy_knc = accuracy_score(y_test,Y_pred_knc) accuracy_knc . 0.7953333333333333 . recall_score(X_test_scaled, y_test) . ValueError Traceback (most recent call last) c: Users Robin Downloads capstone_project _notebooks modelling.ipynb Cell 13 in &lt;cell line: 2&gt;() &lt;a href=&#39;vscode-notebook-cell:/c%3A/Users/Robin/Downloads/capstone_project/_notebooks/modelling.ipynb#ch0000009?line=0&#39;&gt;1&lt;/a&gt; # recall_score(true labels, predicted labels) -&gt; &lt;a href=&#39;vscode-notebook-cell:/c%3A/Users/Robin/Downloads/capstone_project/_notebooks/modelling.ipynb#ch0000009?line=1&#39;&gt;2&lt;/a&gt; recall_score(X_test_scaled, y_test) File c: Users Robin anaconda3 lib site-packages sklearn metrics _classification.py:1901, in recall_score(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division) 1770 def recall_score( 1771 y_true, 1772 y_pred, (...) 1778 zero_division=&#34;warn&#34;, 1779 ): 1780 &#34;&#34;&#34;Compute the recall. 1781 1782 The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of (...) 1899 array([1. , 1. , 0.5]) 1900 &#34;&#34;&#34; -&gt; 1901 _, r, _, _ = precision_recall_fscore_support( 1902 y_true, 1903 y_pred, 1904 labels=labels, 1905 pos_label=pos_label, 1906 average=average, 1907 warn_for=(&#34;recall&#34;,), 1908 sample_weight=sample_weight, 1909 zero_division=zero_division, 1910 ) 1911 return r File c: Users Robin anaconda3 lib site-packages sklearn metrics _classification.py:1544, in precision_recall_fscore_support(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division) 1542 if beta &lt; 0: 1543 raise ValueError(&#34;beta should be &gt;=0 in the F-beta score&#34;) -&gt; 1544 labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label) 1546 # Calculate tp_sum, pred_sum, true_sum ### 1547 samplewise = average == &#34;samples&#34; File c: Users Robin anaconda3 lib site-packages sklearn metrics _classification.py:1348, in _check_set_wise_labels(y_true, y_pred, average, labels, pos_label) 1345 if average not in average_options and average != &#34;binary&#34;: 1346 raise ValueError(&#34;average has to be one of &#34; + str(average_options)) -&gt; 1348 y_type, y_true, y_pred = _check_targets(y_true, y_pred) 1349 # Convert to Python primitive type to avoid NumPy type / Python str 1350 # comparison. See https://github.com/numpy/numpy/issues/6784 1351 present_labels = unique_labels(y_true, y_pred).tolist() File c: Users Robin anaconda3 lib site-packages sklearn metrics _classification.py:93, in _check_targets(y_true, y_pred) 90 y_type = {&#34;multiclass&#34;} 92 if len(y_type) &gt; 1: &gt; 93 raise ValueError( 94 &#34;Classification metrics can&#39;t handle a mix of {0} and {1} targets&#34;.format( 95 type_true, type_pred 96 ) 97 ) 99 # We can&#39;t have more than one value on y_type =&gt; The set is no more needed 100 y_type = y_type.pop() ValueError: Classification metrics can&#39;t handle a mix of continuous-multioutput and binary targets . knc.score(X_train_scaled,y_train) . 0.83975 . from sklearn.metrics import plot_confusion_matrix plot_confusion_matrix(Y_pred_knc, y_test) . from sklearn.svm import LinearSVC SVM_model = LinearSVC() SVM_model.fit(X_train_scaled, y_train) Y_pred_svm = SVM_model.predict(X_test_scaled) print(f&quot;The TRAIN classification accuracy is: {SVM_model.score(X_train, y_train)}&quot;) recall_score(y_test, Y_pred_svm) accuracy_svm = accuracy_score(y_test,Y_pred_svm) accuracy_svm . import imblearn print(imblearn.__version__) # check it was installed properly . 0.9.1 . counter=Counter(y) . NameError Traceback (most recent call last) c: Users Robin Downloads capstone_project _notebooks modelling.ipynb Cell 19 in &lt;cell line: 1&gt;() -&gt; &lt;a href=&#39;vscode-notebook-cell:/c%3A/Users/Robin/Downloads/capstone_project/_notebooks/modelling.ipynb#ch0000018?line=0&#39;&gt;1&lt;/a&gt; counter=Counter(y) NameError: name &#39;Counter&#39; is not defined . oversample=SMOTE() X,y = oversample.fit_resample(X,y) . NameError Traceback (most recent call last) c: Users Robin Downloads capstone_project _notebooks modelling.ipynb Cell 20 in &lt;cell line: 1&gt;() -&gt; &lt;a href=&#39;vscode-notebook-cell:/c%3A/Users/Robin/Downloads/capstone_project/_notebooks/modelling.ipynb#ch0000019?line=0&#39;&gt;1&lt;/a&gt; oversample=SMOTE() &lt;a href=&#39;vscode-notebook-cell:/c%3A/Users/Robin/Downloads/capstone_project/_notebooks/modelling.ipynb#ch0000019?line=1&#39;&gt;2&lt;/a&gt; X,y = oversample.fit_resample(X,y) NameError: name &#39;SMOTE&#39; is not defined .",
            "url": "https://apayal.github.io/capstone_project/2022/08/01/modelling.html",
            "relUrl": "/2022/08/01/modelling.html",
            "date": " • Aug 1, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Credit Card Payment Default",
            "content": "Business Question . Can we accurately predict the probability of a customer defaulting on their payments? . import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns . credit_df=pd.read_csv(r&#39;C: Users Robin Downloads capstone_project _data taiwan_data.csv&#39;) . Data dictionary . &#39;ID&#39;: ID of each client | LIMIT_BAL: Amount of given credit in NT dollars (includes individual and family/supplementary credit | SEX: Gender (1=male, 2=female) | EDUCATION: (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown) | MARRIAGE: Marital status (1=married, 2=single, 3=others) | AGE: Age in years | PAY_0: Repayment status in September, 2005 (-1=pay duly, 1=payment delay for one month, 2=payment delay for two months, … 8=payment delay for eight months, 9=payment delay for nine months and above) | PAY_2: Repayment status in August, 2005 (scale same as above) | PAY_3: Repayment status in July, 2005 (scale same as above) | PAY_4: Repayment status in June, 2005 (scale same as above) | PAY_5: Repayment status in May, 2005 (scale same as above) | PAY_6: Repayment status in April, 2005 (scale same as above) | BILL_AMT1: Amount of bill statement in September, 2005 (NT dollar) | BILL_AMT2: Amount of bill statement in August, 2005 (NT dollar) | BILL_AMT3: Amount of bill statement in July, 2005 (NT dollar) | BILL_AMT4: Amount of bill statement in June, 2005 (-NT dollar) | BILL_AMT5: Amount of bill statement in May, 2005 (NT dollar) | BILL_AMT6: Amount of bill statement in April, 2005 (NT dollar) | PAY_AMT1: Amount of previous payment in September, 2005 (NT dollar) | PAY_AMT2: Amount of previous payment in August, 2005 (NT dollar) | PAY_AMT3: Amount of previous payment in July, 2005 (NT dollar) | PAY_AMT4: Amount of previous payment in June, 2005 (NT dollar) | PAY_AMT5: Amount of previous payment in May, 2005 (NT dollar) | PAY_AMT6: Amount of previous payment in April, 2005 (NT dollar) | default.payment.next.month: Default payment (1=yes, 0=no) | . Overview of the data . #credit_df.shape print(f&#39;We have {credit_df.shape[0]} rows and {credit_df.shape[1]} columns in the dataset.&#39;) . We have 30000 rows and 25 columns in the dataset. . credit_df.head() . ID LIMIT_BAL SEX EDUCATION MARRIAGE AGE PAY_0 PAY_2 PAY_3 PAY_4 ... BILL_AMT4 BILL_AMT5 BILL_AMT6 PAY_AMT1 PAY_AMT2 PAY_AMT3 PAY_AMT4 PAY_AMT5 PAY_AMT6 default payment next month . 0 1 | 20000 | 2 | 2 | 1 | 24 | 2 | 2 | -1 | -1 | ... | 0 | 0 | 0 | 0 | 689 | 0 | 0 | 0 | 0 | 1 | . 1 2 | 120000 | 2 | 2 | 2 | 26 | -1 | 2 | 0 | 0 | ... | 3272 | 3455 | 3261 | 0 | 1000 | 1000 | 1000 | 0 | 2000 | 1 | . 2 3 | 90000 | 2 | 2 | 2 | 34 | 0 | 0 | 0 | 0 | ... | 14331 | 14948 | 15549 | 1518 | 1500 | 1000 | 1000 | 1000 | 5000 | 0 | . 3 4 | 50000 | 2 | 2 | 1 | 37 | 0 | 0 | 0 | 0 | ... | 28314 | 28959 | 29547 | 2000 | 2019 | 1200 | 1100 | 1069 | 1000 | 0 | . 4 5 | 50000 | 1 | 2 | 1 | 57 | -1 | 0 | -1 | 0 | ... | 20940 | 19146 | 19131 | 2000 | 36681 | 10000 | 9000 | 689 | 679 | 0 | . 5 rows × 25 columns . credit_df.tail() . ID LIMIT_BAL SEX EDUCATION MARRIAGE AGE PAY_0 PAY_2 PAY_3 PAY_4 ... BILL_AMT4 BILL_AMT5 BILL_AMT6 PAY_AMT1 PAY_AMT2 PAY_AMT3 PAY_AMT4 PAY_AMT5 PAY_AMT6 default payment next month . 29995 29996 | 220000 | 1 | 3 | 1 | 39 | 0 | 0 | 0 | 0 | ... | 88004 | 31237 | 15980 | 8500 | 20000 | 5003 | 3047 | 5000 | 1000 | 0 | . 29996 29997 | 150000 | 1 | 3 | 2 | 43 | -1 | -1 | -1 | -1 | ... | 8979 | 5190 | 0 | 1837 | 3526 | 8998 | 129 | 0 | 0 | 0 | . 29997 29998 | 30000 | 1 | 2 | 2 | 37 | 4 | 3 | 2 | -1 | ... | 20878 | 20582 | 19357 | 0 | 0 | 22000 | 4200 | 2000 | 3100 | 1 | . 29998 29999 | 80000 | 1 | 3 | 1 | 41 | 1 | -1 | 0 | 0 | ... | 52774 | 11855 | 48944 | 85900 | 3409 | 1178 | 1926 | 52964 | 1804 | 1 | . 29999 30000 | 50000 | 1 | 2 | 1 | 46 | 0 | 0 | 0 | 0 | ... | 36535 | 32428 | 15313 | 2078 | 1800 | 1430 | 1000 | 1000 | 1000 | 1 | . 5 rows × 25 columns . credit_df.describe() . ID LIMIT_BAL SEX EDUCATION MARRIAGE AGE PAY_0 PAY_2 PAY_3 PAY_4 ... BILL_AMT4 BILL_AMT5 BILL_AMT6 PAY_AMT1 PAY_AMT2 PAY_AMT3 PAY_AMT4 PAY_AMT5 PAY_AMT6 default payment next month . count 30000.000000 | 30000.000000 | 30000.000000 | 30000.000000 | 30000.000000 | 30000.000000 | 30000.000000 | 30000.000000 | 30000.000000 | 30000.000000 | ... | 30000.000000 | 30000.000000 | 30000.000000 | 30000.000000 | 3.000000e+04 | 30000.00000 | 30000.000000 | 30000.000000 | 30000.000000 | 30000.000000 | . mean 15000.500000 | 167484.322667 | 1.603733 | 1.853133 | 1.551867 | 35.485500 | -0.016700 | -0.133767 | -0.166200 | -0.220667 | ... | 43262.948967 | 40311.400967 | 38871.760400 | 5663.580500 | 5.921163e+03 | 5225.68150 | 4826.076867 | 4799.387633 | 5215.502567 | 0.221200 | . std 8660.398374 | 129747.661567 | 0.489129 | 0.790349 | 0.521970 | 9.217904 | 1.123802 | 1.197186 | 1.196868 | 1.169139 | ... | 64332.856134 | 60797.155770 | 59554.107537 | 16563.280354 | 2.304087e+04 | 17606.96147 | 15666.159744 | 15278.305679 | 17777.465775 | 0.415062 | . min 1.000000 | 10000.000000 | 1.000000 | 0.000000 | 0.000000 | 21.000000 | -2.000000 | -2.000000 | -2.000000 | -2.000000 | ... | -170000.000000 | -81334.000000 | -339603.000000 | 0.000000 | 0.000000e+00 | 0.00000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | . 25% 7500.750000 | 50000.000000 | 1.000000 | 1.000000 | 1.000000 | 28.000000 | -1.000000 | -1.000000 | -1.000000 | -1.000000 | ... | 2326.750000 | 1763.000000 | 1256.000000 | 1000.000000 | 8.330000e+02 | 390.00000 | 296.000000 | 252.500000 | 117.750000 | 0.000000 | . 50% 15000.500000 | 140000.000000 | 2.000000 | 2.000000 | 2.000000 | 34.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | ... | 19052.000000 | 18104.500000 | 17071.000000 | 2100.000000 | 2.009000e+03 | 1800.00000 | 1500.000000 | 1500.000000 | 1500.000000 | 0.000000 | . 75% 22500.250000 | 240000.000000 | 2.000000 | 2.000000 | 2.000000 | 41.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | ... | 54506.000000 | 50190.500000 | 49198.250000 | 5006.000000 | 5.000000e+03 | 4505.00000 | 4013.250000 | 4031.500000 | 4000.000000 | 0.000000 | . max 30000.000000 | 1000000.000000 | 2.000000 | 6.000000 | 3.000000 | 79.000000 | 8.000000 | 8.000000 | 8.000000 | 8.000000 | ... | 891586.000000 | 927171.000000 | 961664.000000 | 873552.000000 | 1.684259e+06 | 896040.00000 | 621000.000000 | 426529.000000 | 528666.000000 | 1.000000 | . 8 rows × 25 columns . Data cleaning and preprocessing . #print(f&#39;We have {credit_df.isna().sum()} rows and {credit_df.shape[1]} columns in the dataset.&#39;) credit_df.isna().sum() . ID 0 LIMIT_BAL 0 SEX 0 EDUCATION 0 MARRIAGE 0 AGE 0 PAY_0 0 PAY_2 0 PAY_3 0 PAY_4 0 PAY_5 0 PAY_6 0 BILL_AMT1 0 BILL_AMT2 0 BILL_AMT3 0 BILL_AMT4 0 BILL_AMT5 0 BILL_AMT6 0 PAY_AMT1 0 PAY_AMT2 0 PAY_AMT3 0 PAY_AMT4 0 PAY_AMT5 0 PAY_AMT6 0 default payment next month 0 dtype: int64 . credit_df.duplicated().sum() . 0 . pd.DataFrame(credit_df.columns) #looking at columns names to check all the column names are appropriate . 0 . 0 ID | . 1 LIMIT_BAL | . 2 SEX | . 3 EDUCATION | . 4 MARRIAGE | . 5 AGE | . 6 PAY_0 | . 7 PAY_2 | . 8 PAY_3 | . 9 PAY_4 | . 10 PAY_5 | . 11 PAY_6 | . 12 BILL_AMT1 | . 13 BILL_AMT2 | . 14 BILL_AMT3 | . 15 BILL_AMT4 | . 16 BILL_AMT5 | . 17 BILL_AMT6 | . 18 PAY_AMT1 | . 19 PAY_AMT2 | . 20 PAY_AMT3 | . 21 PAY_AMT4 | . 22 PAY_AMT5 | . 23 PAY_AMT6 | . 24 default payment next month | . The sixth column starts at PAY_0 but then skips to PAY_2. Looking at the other columns in a group such as BILL_AMT and PAY_AMT they all start at 1 and go up to 6. So we need to rename the column PAY_0 as PAY_1 so it has the same format as the other columns and avoid confusion. . Default payment next month is the target column i.e the one we want to predict. This column name should also be changed for easier access,reference and most importantly so it follows the same uniform naming convention as the other columns - 1 or 2 words in capitals that succinctly describes the data contained in the column. . new_column_names = {&#39;PAY_0&#39;: &#39;PAY_1&#39;, &#39;default payment next month&#39;:&#39;DEFAULT&#39; } . credit_df.rename(columns=new_column_names,inplace=True) . credit_df.info() # check they have been changed . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 30000 entries, 0 to 29999 Data columns (total 25 columns): # Column Non-Null Count Dtype -- -- 0 ID 30000 non-null int64 1 LIMIT_BAL 30000 non-null int64 2 SEX 30000 non-null int64 3 EDUCATION 30000 non-null int64 4 MARRIAGE 30000 non-null int64 5 AGE 30000 non-null int64 6 PAY_1 30000 non-null int64 7 PAY_2 30000 non-null int64 8 PAY_3 30000 non-null int64 9 PAY_4 30000 non-null int64 10 PAY_5 30000 non-null int64 11 PAY_6 30000 non-null int64 12 BILL_AMT1 30000 non-null int64 13 BILL_AMT2 30000 non-null int64 14 BILL_AMT3 30000 non-null int64 15 BILL_AMT4 30000 non-null int64 16 BILL_AMT5 30000 non-null int64 17 BILL_AMT6 30000 non-null int64 18 PAY_AMT1 30000 non-null int64 19 PAY_AMT2 30000 non-null int64 20 PAY_AMT3 30000 non-null int64 21 PAY_AMT4 30000 non-null int64 22 PAY_AMT5 30000 non-null int64 23 PAY_AMT6 30000 non-null int64 24 DEFAULT 30000 non-null int64 dtypes: int64(25) memory usage: 5.7 MB . Lets focus on cleaning and checking for inconsistencies in the demographic columns of the dataset first. . 1. SEX . From the data dictionary we already know that sex has the values 1 and 2 representing male and female. However in computing binary values are traditionally represented as 0 and 1, so we will change them. . credit_df[&#39;SEX&#39;] . 0 2 1 2 2 2 3 2 4 1 .. 29995 1 29996 1 29997 1 29998 1 29999 1 Name: SEX, Length: 30000, dtype: int64 . credit_df[&#39;SEX&#39;]=credit_df[&#39;SEX&#39;].replace({1: 0, 2: 1}) . credit_df[&#39;SEX&#39;].value_counts() # check we only have 0 and 1 left . 1 18112 0 11888 Name: SEX, dtype: int64 . Education . Education also has some extra values. We already know there is 2 redundent values of 5 and 6. We have 4 to denote unknown or other education status. We can do a value counts to check if there are anymore unknown values and if there is also assign them to 4. . credit_df[&#39;EDUCATION&#39;].value_counts(normalize=True)*100 # as suspected another unknown value - 0,not mentioned in description . 2 46.766667 1 35.283333 3 16.390000 5 0.933333 4 0.410000 6 0.170000 0 0.046667 Name: EDUCATION, dtype: float64 . credit_df[&#39;EDUCATION&#39;]=credit_df[&#39;EDUCATION&#39;].replace([0,5,6], 4 ) credit_df[&#39;EDUCATION&#39;].value_counts(normalize=True)*100 # now do get dummies so we only have 3 columns left . 2 46.766667 1 35.283333 3 16.390000 4 1.560000 Name: EDUCATION, dtype: float64 . There is actually 3 unknown values: 0,5,6. We can map these to the value 4 to refer to other either instituations or other unknown place of study. . However upon doing some external reseach, I found that Taiwan has a very high percentage of education completion in general. In fact around 94.7% of people have passed high school and gone onto some sort of higher education or senior vocational course . Based on this information, it is safe to assume that the unknown values and other category can be grouped together in the value 3, as it is highly likely that these people have passed high school at very the least. Additionally since adding the 3 unknown values to 4 gives us 468 values which accounts for less than 1.56% of the entire column it is insignificant in making predictions which means it can only contribute to making models more computationally expensive to compute. . education_df = pd.get_dummies(credit_df[&#39;EDUCATION&#39;],prefix=&#39;Education&#39;) # or undo this and just do a get dummies instead . education_df.drop(columns=[&#39;Education_4&#39;], inplace=True) . education_df . Education_1 Education_2 Education_3 . 0 0 | 1 | 0 | . 1 0 | 1 | 0 | . 2 0 | 1 | 0 | . 3 0 | 1 | 0 | . 4 0 | 1 | 0 | . ... ... | ... | ... | . 29995 0 | 0 | 1 | . 29996 0 | 0 | 1 | . 29997 0 | 1 | 0 | . 29998 0 | 0 | 1 | . 29999 0 | 1 | 0 | . 30000 rows × 3 columns . education_df.value_counts() . Education_1 Education_2 Education_3 0 1 0 14030 1 0 0 10585 0 0 1 4917 0 468 dtype: int64 . Marriage . This also has 1 unknown value of 0, which we can change to 3 (others) . credit_df[&#39;MARRIAGE&#39;].value_counts() . 2 15964 1 13659 3 323 0 54 Name: MARRIAGE, dtype: int64 . credit_df[&#39;MARRIAGE&#39;]=credit_df[&#39;MARRIAGE&#39;].replace(0,3) . credit_df[&#39;MARRIAGE&#39;].value_counts(normalize=True)*100 . 2 53.213333 1 45.530000 3 1.256667 Name: MARRIAGE, dtype: float64 . Married and single can essentially be represented as 1 columns of married or not. Although value 3 only accounts for 1.25% of the column we can at the moment have a separate column for it but later when we do PCA or feature engineering I suspect it will be unimportant in predictions ans thus will be removed or not included in the modelling. . credit_df[&#39;MARRIAGE&#39;] . 0 1 1 2 2 2 3 1 4 1 .. 29995 1 29996 2 29997 2 29998 1 29999 1 Name: MARRIAGE, Length: 30000, dtype: int64 . marriage_df=pd.get_dummies(credit_df[&#39;MARRIAGE&#39;],prefix=&#39;Marital_status&#39;,drop_first=True) . marriage_df . Marital_status_2 Marital_status_3 . 0 0 | 0 | . 1 1 | 0 | . 2 1 | 0 | . 3 0 | 0 | . 4 0 | 0 | . ... ... | ... | . 29995 0 | 0 | . 29996 1 | 0 | . 29997 1 | 0 | . 29998 0 | 0 | . 29999 0 | 0 | . 30000 rows × 2 columns . . credit_df_clean = pd.concat([credit_df,education_df, marriage_df], axis=1) credit_df_clean.head() . ID LIMIT_BAL SEX EDUCATION MARRIAGE AGE PAY_1 PAY_2 PAY_3 PAY_4 ... PAY_AMT3 PAY_AMT4 PAY_AMT5 PAY_AMT6 DEFAULT Education_1 Education_2 Education_3 Marital_status_2 Marital_status_3 . 0 1 | 20000 | 1 | 2 | 1 | 24 | 2 | 2 | -1 | -1 | ... | 0 | 0 | 0 | 0 | 1 | 0 | 1 | 0 | 0 | 0 | . 1 2 | 120000 | 1 | 2 | 2 | 26 | -1 | 2 | 0 | 0 | ... | 1000 | 1000 | 0 | 2000 | 1 | 0 | 1 | 0 | 1 | 0 | . 2 3 | 90000 | 1 | 2 | 2 | 34 | 0 | 0 | 0 | 0 | ... | 1000 | 1000 | 1000 | 5000 | 0 | 0 | 1 | 0 | 1 | 0 | . 3 4 | 50000 | 1 | 2 | 1 | 37 | 0 | 0 | 0 | 0 | ... | 1200 | 1100 | 1069 | 1000 | 0 | 0 | 1 | 0 | 0 | 0 | . 4 5 | 50000 | 0 | 2 | 1 | 57 | -1 | 0 | -1 | 0 | ... | 10000 | 9000 | 689 | 679 | 0 | 0 | 1 | 0 | 0 | 0 | . 5 rows × 30 columns . rename_col = {&#39;Education_1&#39;: &#39;Education_higher&#39;, &#39;Education_2&#39;:&#39;Education_university&#39;, &#39;Education_3&#39;:&#39;Education_highschool&#39;, &#39;Marital_status_2&#39;:&#39;Marriage_Single&#39;, &#39;Marital_status_3&#39;:&#39;Marriage_Other&#39; } . credit_df_clean.rename(columns=rename_col,inplace=True) credit_df_clean.head() . ID LIMIT_BAL SEX EDUCATION MARRIAGE AGE PAY_1 PAY_2 PAY_3 PAY_4 ... PAY_AMT3 PAY_AMT4 PAY_AMT5 PAY_AMT6 DEFAULT Education_higher Education_university Education_highschool Marriage_Single Marriage_Other . 0 1 | 20000 | 1 | 2 | 1 | 24 | 2 | 2 | -1 | -1 | ... | 0 | 0 | 0 | 0 | 1 | 0 | 1 | 0 | 0 | 0 | . 1 2 | 120000 | 1 | 2 | 2 | 26 | -1 | 2 | 0 | 0 | ... | 1000 | 1000 | 0 | 2000 | 1 | 0 | 1 | 0 | 1 | 0 | . 2 3 | 90000 | 1 | 2 | 2 | 34 | 0 | 0 | 0 | 0 | ... | 1000 | 1000 | 1000 | 5000 | 0 | 0 | 1 | 0 | 1 | 0 | . 3 4 | 50000 | 1 | 2 | 1 | 37 | 0 | 0 | 0 | 0 | ... | 1200 | 1100 | 1069 | 1000 | 0 | 0 | 1 | 0 | 0 | 0 | . 4 5 | 50000 | 0 | 2 | 1 | 57 | -1 | 0 | -1 | 0 | ... | 10000 | 9000 | 689 | 679 | 0 | 0 | 1 | 0 | 0 | 0 | . 5 rows × 30 columns . credit_df_clean=credit_df_clean.drop(columns=[&#39;EDUCATION&#39;,&#39;MARRIAGE&#39;]) . credit_df_clean . ID LIMIT_BAL SEX AGE PAY_1 PAY_2 PAY_3 PAY_4 PAY_5 PAY_6 ... PAY_AMT3 PAY_AMT4 PAY_AMT5 PAY_AMT6 DEFAULT Education_higher Education_university Education_highschool Marriage_Single Marriage_Other . 0 1 | 20000 | 1 | 24 | 2 | 2 | -1 | -1 | -2 | -2 | ... | 0 | 0 | 0 | 0 | 1 | 0 | 1 | 0 | 0 | 0 | . 1 2 | 120000 | 1 | 26 | -1 | 2 | 0 | 0 | 0 | 2 | ... | 1000 | 1000 | 0 | 2000 | 1 | 0 | 1 | 0 | 1 | 0 | . 2 3 | 90000 | 1 | 34 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 1000 | 1000 | 1000 | 5000 | 0 | 0 | 1 | 0 | 1 | 0 | . 3 4 | 50000 | 1 | 37 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 1200 | 1100 | 1069 | 1000 | 0 | 0 | 1 | 0 | 0 | 0 | . 4 5 | 50000 | 0 | 57 | -1 | 0 | -1 | 0 | 0 | 0 | ... | 10000 | 9000 | 689 | 679 | 0 | 0 | 1 | 0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 29995 29996 | 220000 | 0 | 39 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 5003 | 3047 | 5000 | 1000 | 0 | 0 | 0 | 1 | 0 | 0 | . 29996 29997 | 150000 | 0 | 43 | -1 | -1 | -1 | -1 | 0 | 0 | ... | 8998 | 129 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 0 | . 29997 29998 | 30000 | 0 | 37 | 4 | 3 | 2 | -1 | 0 | 0 | ... | 22000 | 4200 | 2000 | 3100 | 1 | 0 | 1 | 0 | 1 | 0 | . 29998 29999 | 80000 | 0 | 41 | 1 | -1 | 0 | 0 | 0 | -1 | ... | 1178 | 1926 | 52964 | 1804 | 1 | 0 | 0 | 1 | 0 | 0 | . 29999 30000 | 50000 | 0 | 46 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 1430 | 1000 | 1000 | 1000 | 1 | 0 | 1 | 0 | 0 | 0 | . 30000 rows × 28 columns . Demographic observations . The ID column is just an identifier, which also has no predictive value this is something we can remove later when modelling. . #color=sns.color_palette(&quot;rocket&quot;) plt.figure(figsize=(9,6)) sns.histplot(data=credit_df[&#39;LIMIT_BAL&#39;],bins=50,kde=True) plt.title(&#39;Distribution of Limit balance&#39;) plt.show() . #credit_df[&#39;LIMIT_BAL&#39;].value_counts(5).plot(kind=&#39;bar&#39;) colors = sns.color_palette(&#39;rocket&#39;) credit_df[&#39;LIMIT_BAL&#39;].value_counts().head(3).plot(kind=&#39;bar&#39;,color=&#39;coral&#39;) . &lt;AxesSubplot:&gt; . The most common credit balance limits are 50k, 20k and 30k respectively. Compared to the minimum 10k and maximum of 1000000 the figures are on the lower end of the range. However the maximum amount could be a outlier as its more than 2 standard deviations away from the mean. . # Marriage, Age, and Sex def boxplot_variation(feature1, feature2, feature3, width=16): fig, ax1 = plt.subplots(ncols=1, figsize=(width, 6)) s = sns.boxplot(ax=ax1, x=feature1, y=feature2, hue=feature3, data=credit_df, palette=&#39;pastel&#39;) #s.set_xticklabels(s.get_xticklabels(), rotation=90) plt.show(); boxplot_variation(&#39;MARRIAGE&#39;, &#39;AGE&#39;, &#39;SEX&#39;, 10) . boxplot_variation(&#39;EDUCATION&#39;, &#39;LIMIT_BAL&#39;, &#39;DEFAULT&#39;, 10) . credit_df_pay_col=credit_df_clean.columns[4:10] . for month in credit_df_pay_col: print(sorted(credit_df_clean[month].unique())) . [-2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8] [-2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8] [-2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8] [-2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8] [-2, -1, 0, 2, 3, 4, 5, 6, 7, 8] [-2, -1, 0, 2, 3, 4, 5, 6, 7, 8] . # credit_df = credit_df.replace([-1, -2], 0 ) # or can put to scale from 0 - 10? ############ # These ranges are not mentioned in the description, let&#39;s change the range to 0-10? # old_range = [-2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8] # new_range = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] for month in credit_df_clean.columns[4:10]: credit_df_clean[month]=credit_df_clean[month]+1 # inplace=True) # can just add 1 #credit_df_clean[&#39;PAY_1&#39;]=credit_df_clean[&#39;PAY_1&#39;]+1 credit_df_clean[&#39;PAY_1&#39;].value_counts() . 1 14737 0 5686 2 3688 -1 2759 3 2667 4 322 5 76 6 26 9 19 7 11 8 9 Name: PAY_1, dtype: int64 . credit_df[&#39;BILL_AMT1&#39;].value_counts().sort_values() . 4984 1 133572 1 24132 1 114227 1 30415 1 ... 316 63 326 72 780 76 390 244 0 2008 Name: BILL_AMT1, Length: 22723, dtype: int64 . for col in credit_df_clean.columns[4:20]: plt.subplots(1, 2, figsize = (8, 3)) plt.tight_layout() plt.subplot(1, 2, 1) plt.title(f&#39;Original: {col}&#39;) sns.histplot(credit_df_clean[col], bins = 40) plt.subplot(1, 2, 2) plt.title(f&#39;Log transformed: {col}&#39;) sns.histplot(credit_df_clean[col], bins = 40) plt.yscale(&#39;log&#39;) plt.show() . for col in credit_df_clean.columns[4:20]: plt.figure() plt.title(f&#39;Feature: {col}&#39;) sns.histplot(credit_df_clean[col],bins=30) plt.yscale(&#39;log&#39;) plt.show() . Target column - default . colours = sns.color_palette(&#39;Set2&#39;)[0:5] (credit_df[&#39;DEFAULT&#39;].value_counts(normalize=True)*100).plot(kind=&#39;pie&#39;,autopct=&#39;%.0f%%&#39;,colors=colours,legend=True, figsize=(14,6),startangle=75) plt.legend([&#39;0:Not default&#39;,&#39;1: Default&#39;],loc=&#39;lower right&#39;) plt.title(&#39;Default on payment next month?&#39;) plt.show() . # v=credit_df[&#39;DEFAULT&#39;].value_counts(normalize=True)*100 # fig= px.pie(credit_df) # fig.show() . Very imbalanced dataset. This is normal as most people will have paid thier credit card bill on time. However I will have to do upsampling on the smaller class to avoid bias to the majority class, which can cause the number of false negatives predicted to be higher. . #credit_df.iloc[:,12:25] plt.figure(figsize=(10,7)) cmap = sns.diverging_palette(230, 20, as_cmap=True) sns.heatmap(credit_df.iloc[:,12:25].corr(),annot=True,cmap=cmap) . &lt;AxesSubplot:&gt; . corr = credit_df_clean.corr(method=&#39;spearman&#39;) mask = np.zeros_like(corr,dtype=bool) mask[np.triu_indices_from(mask)]=True cmap = sns.diverging_palette(230, 20, as_cmap=True) with sns.axes_style(&quot;white&quot;): plt.subplots(figsize=(18, 18)) sns.heatmap(corr, mask=mask, square=True, linewidths=.3, fmt=&#39;.2f&#39;, cmap=cmap, annot=True, annot_kws={&quot;size&quot;: 12}) plt.title(&#39;Correlation matrix&#39;, size=15) plt.show() #ref - https://seaborn.pydata.org/examples/many_pairwise_correlations.html . loads of correlated columns - will have to do PCA on this. notably with the default column limit bal is negatively correlated and pay_1 has the highest correlation followed by the res of the pay columns. . cols_at_end = [&#39;&#39;] df = df[[c for c in df if c not in cols_at_end] + [c for c in cols_at_end if c in df]] . credit_df_clean.to_csv(&#39;credit-df-dataset-cleaned.csv&#39;, index=False) # the index column will not be saved .",
            "url": "https://apayal.github.io/capstone_project/2022/07/01/eda.html",
            "relUrl": "/2022/07/01/eda.html",
            "date": " • Jul 1, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://apayal.github.io/capstone_project/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://apayal.github.io/capstone_project/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://apayal.github.io/capstone_project/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://apayal.github.io/capstone_project/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}